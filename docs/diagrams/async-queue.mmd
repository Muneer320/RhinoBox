```mermaid
graph TB
    subgraph API["API Layer"]
        HANDLER[Request Handler]
        VALIDATOR[Input Validator]
    end
    
    subgraph QUEUE["Job Queue (Buffered Channel)"]
        BUFFER[Channel Buffer<br/>capacity: 1000]
    end
    
    subgraph WORKERS["Worker Pool (10 Goroutines)"]
        W1[Worker 1]
        W2[Worker 2]
        W3[Worker 3]
        W4[Worker 4]
        W5[Worker 5]
        W6[Worker 6]
        W7[Worker 7]
        W8[Worker 8]
        W9[Worker 9]
        W10[Worker 10]
    end
    
    subgraph PROCESSING["Processing Pipeline"]
        MIME[MIME Detection]
        HASH[SHA-256 Hash]
        DEDUP[Dedup Check]
        STORE[File Storage]
        JSONPARSE[JSON Parser]
        ANALYZER[Schema Analyzer]
        DECISION[Decision Engine]
    end
    
    subgraph STORAGE["Storage Backends"]
        FS[Filesystem]
        PG[PostgreSQL]
        MG[MongoDB]
        CACHE[BadgerDB Cache]
    end
    
    subgraph MONITOR["Monitoring"]
        METRICS[Prometheus Metrics<br/>queue_size<br/>enqueue_time<br/>processing_time]
        HEALTH[Health Check<br/>/health endpoint]
    end
    
    HANDLER --> VALIDATOR
    VALIDATOR -->|Valid| BUFFER
    VALIDATOR -->|Invalid| ERROR[400 Bad Request]
    
    BUFFER -->|Non-blocking enqueue<br/>596µs avg| W1
    BUFFER --> W2
    BUFFER --> W3
    BUFFER --> W4
    BUFFER --> W5
    BUFFER --> W6
    BUFFER --> W7
    BUFFER --> W8
    BUFFER --> W9
    BUFFER --> W10
    
    W1 --> MIME
    W2 --> MIME
    W3 --> MIME
    W4 --> MIME
    W5 --> MIME
    W6 --> JSONPARSE
    W7 --> JSONPARSE
    W8 --> JSONPARSE
    W9 --> JSONPARSE
    W10 --> JSONPARSE
    
    MIME --> HASH
    HASH --> DEDUP
    DEDUP -->|New file| STORE
    DEDUP -->|Duplicate| CACHE
    STORE --> FS
    STORE --> CACHE
    
    JSONPARSE --> ANALYZER
    ANALYZER --> DECISION
    DECISION -->|SQL route| PG
    DECISION -->|NoSQL route| MG
    
    BUFFER -.->|Metrics| METRICS
    W1 -.->|Status| HEALTH
    W2 -.->|Status| HEALTH
    W3 -.->|Status| HEALTH
    
    HANDLER -->|Immediate response<br/>202 Accepted<br/>job_id: uuid| CLIENT[Client]
    CLIENT -->|Poll status| STATUS[GET /jobs/:id]
    STATUS -.->|Query| CACHE
    
    style HANDLER fill:#e1f5ff
    style BUFFER fill:#ffffcc
    style W1 fill:#90ee90
    style W2 fill:#90ee90
    style W3 fill:#90ee90
    style W4 fill:#90ee90
    style W5 fill:#90ee90
    style W6 fill:#ffb6c1
    style W7 fill:#ffb6c1
    style W8 fill:#ffb6c1
    style W9 fill:#ffb6c1
    style W10 fill:#ffb6c1
    style METRICS fill:#ffd700
    style HEALTH fill:#98fb98
```

# Async Job Queue Architecture

This diagram shows the complete asynchronous processing system in RhinoBox, enabling 1000× faster response times for batch operations.

## Architecture Components

### 1. API Layer
- **Request Handler**: Validates input, generates `job_id`
- **Response Time**: <5ms (202 Accepted)
- **Payload Limit**: 10MB per request

### 2. Job Queue (Buffered Channel)
- **Type**: Go buffered channel
- **Capacity**: 1000 jobs
- **Enqueue Time**: 596µs average
- **Overflow Behavior**: HTTP 503 (graceful degradation)
- **Persistence**: Optional BadgerDB backing

### 3. Worker Pool (10 Goroutines)
- **Workers**: 10 concurrent goroutines
- **Lifecycle**: Daemon goroutines (survive restarts)
- **Specialization**:
  - Workers 1-5: Media files (MIME, hash, storage)
  - Workers 6-10: JSON documents (parse, analyze, route)
- **Throughput**: 1677 jobs/sec combined
- **Error Handling**: Retry logic (3 attempts, exponential backoff)

### 4. Processing Pipeline

#### Media Path (Workers 1-5)
1. **MIME Detection**: libmagic-based, 1-3ms
2. **SHA-256 Hash**: Streaming, 1.27ms/MB
3. **Deduplication**: Multi-level cache check (231.5ns - 15µs)
4. **File Storage**: Zero-copy I/O to filesystem
5. **Metadata Indexing**: Cache + optional database

#### JSON Path (Workers 6-10)
1. **JSON Parsing**: Standard library, 1-5ms
2. **Schema Analysis**: Field histograms, 5-20ms/100 docs
3. **Decision Engine**: SQL vs NoSQL routing, 1-2ms
4. **Database Insert**: COPY (PostgreSQL) or BulkWrite (MongoDB)
5. **NDJSON Backup**: Durability guarantee

### 5. Storage Backends
- **Filesystem**: Local or NFS, zero-copy writes
- **PostgreSQL**: COPY protocol, 100K+/sec
- **MongoDB**: BulkWrite, 200K+/sec
- **BadgerDB Cache**: Job status, metadata

### 6. Monitoring
- **Prometheus Metrics**:
  - `rhinobox_queue_size` (current depth)
  - `rhinobox_enqueue_duration_seconds` (histogram)
  - `rhinobox_processing_duration_seconds` (histogram)
  - `rhinobox_worker_status` (gauge)
- **Health Check**: `/health` endpoint, checks worker liveness

## Performance Characteristics

### Throughput
| Metric | Value |
|--------|-------|
| **Enqueue Rate** | 1677 jobs/sec |
| **Enqueue Latency** | 596µs (avg) |
| **Processing Rate** | 1000+ files/sec (media) |
| **Processing Rate** | 2000+ docs/sec (JSON) |
| **Queue Capacity** | 1000 jobs |

### Response Times
| Operation | Sync | Async (with queue) |
|-----------|------|-------------------|
| **Single Upload** | 20-80ms | <5ms (202 Accepted) |
| **Batch 100 files** | 2-8 seconds | <5ms (batch job_id) |
| **Batch 1000 docs** | 5-30 seconds | <5ms (batch job_id) |

**Improvement**: 1000× faster API response (5ms vs 5000ms)

### Resource Utilization
- **CPU**: 40-60% (10 workers × 4-6% each)
- **Memory**: ~200MB (1000 job buffer + worker state)
- **Goroutines**: 10 permanent + 2-5 transient

## Job Lifecycle

### 1. Job Submission
```http
POST /ingest/async
Content-Type: multipart/form-data

file=@large_video.mp4&namespace=videos
```

**Response**:
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "queued",
  "position": 42
}
```

### 2. Job Processing
- **Status**: `queued` → `processing` → `completed`/`failed`
- **Progress Tracking**: Via BadgerDB cache
- **TTL**: 1 hour (job metadata)

### 3. Job Status Check
```http
GET /jobs/550e8400-e29b-41d4-a716-446655440000
```

**Response (Completed)**:
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "result": {
    "hash": "abc123...",
    "size": 104857600,
    "type": "video/mp4"
  },
  "duration_ms": 1250
}
```

**Response (Failed)**:
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "failed",
  "error": "disk quota exceeded",
  "attempts": 3
}
```

## Error Handling

### Queue Overflow (HTTP 503)
```json
{
  "error": "queue full",
  "queue_size": 1000,
  "retry_after": 5
}
```
**Client Action**: Retry after 5 seconds (exponential backoff)

### Worker Panic Recovery
- **Behavior**: Goroutine auto-restarts
- **Logging**: Panic stack trace to logs
- **Metrics**: `rhinobox_worker_panics_total` counter

### Database Unavailable
- **Fallback**: NDJSON backup only
- **Status**: Job marked `completed_with_warnings`
- **Reprocessing**: Manual trigger via admin API

## Configuration

### Environment Variables
```bash
ASYNC_QUEUE_SIZE=1000           # Job buffer capacity
ASYNC_WORKER_COUNT=10           # Number of goroutines
ASYNC_MAX_RETRIES=3             # Retry attempts
ASYNC_RETRY_DELAY=1s            # Initial retry delay
ASYNC_JOB_TTL=1h                # Job metadata TTL
ASYNC_ENABLE_PERSISTENCE=true   # BadgerDB backing
```

### Tuning Guidelines
| Scenario | Queue Size | Worker Count |
|----------|-----------|--------------|
| **Low traffic (<100 req/min)** | 500 | 5 |
| **Medium traffic (100-1000 req/min)** | 1000 | 10 |
| **High traffic (>1000 req/min)** | 2000 | 20 |

**CPU Consideration**: Each worker uses ~4-6% CPU under load

## Scalability

### Horizontal Scaling
- **Strategy**: Redis-backed job queue (replace Go channel)
- **Worker Distribution**: Multiple RhinoBox instances consume from shared queue
- **Coordination**: Distributed locks for duplicate prevention

### Vertical Scaling
- **CPU**: More workers (20-50 on 16+ cores)
- **Memory**: Larger queue buffer (2000-5000 jobs)
- **Disk I/O**: NVMe SSD for BadgerDB cache

## Monitoring Dashboard

### Key Metrics (Grafana)
1. **Queue Depth**: `rhinobox_queue_size` (gauge)
   - Alert if >80% capacity for >5min
2. **Enqueue Latency**: `rhinobox_enqueue_duration_seconds` (histogram)
   - P99 should be <5ms
3. **Processing Latency**: `rhinobox_processing_duration_seconds` (histogram)
   - Media P99: <100ms
   - JSON P99: <50ms
4. **Worker Health**: `rhinobox_worker_status` (gauge, 1=healthy, 0=dead)
   - Alert if any worker dead for >1min
5. **Job Failure Rate**: `rhinobox_jobs_failed_total` / `rhinobox_jobs_total`
   - Alert if >5% for >10min

## Trade-offs

### Benefits ✅
- **1000× faster API response** (5ms vs 5000ms)
- **Better resource utilization** (batch processing)
- **Graceful degradation** (queue overflow → HTTP 503)
- **Progress tracking** (job status API)

### Drawbacks ⚠️
- **Increased complexity** (queue management, worker coordination)
- **Memory overhead** (~200MB for 1000-job buffer)
- **Eventual consistency** (results not immediate)
- **Requires monitoring** (queue depth, worker health)

**Verdict**: Essential for production workloads >100 req/min
